import logging
import json
import os
import asyncio
from pyrogram import Client, filters
from pyrogram.enums import ChatAction
import aiohttp
import re
import socket

# Almacena el historial de conversaciones por usuario
CONVERSATION_HISTORY = {}

#logging.basicConfig(level=logging.DEBUG)  # Habilita logs detallados

def update_config(var_name, var_value, config_file="config.json"):
    if os.path.exists(config_file):
        with open(config_file, "r") as file:
            config = json.load(file)
    else:
        config = {}

    config[var_name] = var_value

    with open(config_file, "w") as file:
        json.dump(config, file, indent=4)

def get_config(var_name, default_value, create_var=False, config_file="config.json"):
    # Verifica si el archivo de configuración existe; si no, carga un diccionario vacío
    if os.path.exists(config_file):
        with open(config_file, "r") as file:
            config = json.load(file)
    else:
        config = {}

    # Devuelve el valor de la variable si existe, o el valor por defecto si no
    value = config.get(var_name, default_value)

    # Si la variable no existe y create_var=True, añade la variable con el valor por defecto
    if var_name not in config and create_var:
        update_config(var_name, default_value, config_file)
    return value

def load_config():
    global TOKEN, API_ID, API_HASH, OLLAMA_SERVERS, OLLAMA_CONTEXT, OLLAMA_TEMPERATURE, SERVER_INDEX, config, MAX_HISTORY
    # Cargar configuración desde config.json
    with open("config.json", "r", encoding="utf-8") as file:
        config = json.load(file)

    TOKEN = config["token"]
    API_ID = config["api_id"]
    API_HASH = config["api_hash"]
    OLLAMA_SERVERS = config["servers"]  # Lista de servidores
    OLLAMA_CONTEXT = config["context"]
    OLLAMA_TEMPERATURE = config["temperature"]
    SERVER_INDEX = config["server_index"]  # Índice del servidor actual
    MAX_HISTORY = config["max_history"]  # Mensajes máximos por usuario en memoria
    AUTHORIZED_USERS = config["authorized_users"]
    # Inicializar el cliente de Pyrogram

load_config()
bot_name=f"TeleBotGPT_{socket.gethostname()}"
bot = Client(f"{bot_name}", bot_token=TOKEN, api_id=API_ID, api_hash=API_HASH)
#bot.start()
print(f"Bot {bot_name} configured")

   
def load_conversation_history(user_id):
    """Carga el historial de conversación desde un archivo JSON si existe."""
    file_path = f"{user_id}.json"
    if os.path.exists(file_path):
        with open(file_path, "r", encoding="utf-8") as file:
            return json.load(file)
    return []

def save_conversation_history(user_id):
    """Guarda el historial de conversación en un archivo JSON."""
    file_path = f"{user_id}.json"
    with open(file_path, "w", encoding="utf-8") as file:
        json.dump(CONVERSATION_HISTORY[user_id], file, ensure_ascii=False, indent=4)

def get_current_server():
    """Devuelve la URL del servidor actual."""
    host, port, alias, model = OLLAMA_SERVERS[SERVER_INDEX]
    return f"http://{host}:{port}/api/generate", model, alias

def update_conversation_history(user_id, user_message, bot_response):
    global MAX_HISTORY, CONVERSATION_HISTORY
    """Añadir mensaje al historial del usuario y limitar a MAX_HISTORY."""
    if user_id not in CONVERSATION_HISTORY:
        CONVERSATION_HISTORY[user_id] = []
    
    # Agregar mensaje del usuario y respuesta del bot
    CONVERSATION_HISTORY[user_id].append(f"User: {user_message}")
    bot_response = remove_thinking_tags(bot_response)
    CONVERSATION_HISTORY[user_id].append(f"Bot: {bot_response}")

    # Limitar el historial a los últimos MAX_HISTORY mensajes
    CONVERSATION_HISTORY[user_id] = CONVERSATION_HISTORY[user_id][-MAX_HISTORY:]

    # Guardar el historial actualizado en el archivo JSON
    save_conversation_history(user_id)
    
async def query_ollama(prompt, client, message):
    """Enviar el mensaje al servidor Ollama y obtener la respuesta del LLM."""
    global SERVER_INDEX, CONVERSATION_HISTORY

    user_id = message.from_user.id
    
    if user_id not in CONVERSATION_HISTORY:
        # Cargar historial si existe
        CONVERSATION_HISTORY[user_id] = load_conversation_history(user_id)
    
    history = "\n".join(CONVERSATION_HISTORY.get(user_id, []))  # Obtener historial previo
    history = truncate_message(history)
    #print(f"##############################HISTORY")
    #print (f"history={history}")
    #print(f"##############################")
    for _ in range(len(OLLAMA_SERVERS)):  # Intentar en todos los servidores
        OLLAMA_URL, OLLAMA_MODEL, alias = get_current_server()
        payload = {
            "model": OLLAMA_MODEL,
            #"prompt": f"{OLLAMA_CONTEXT}: {prompt}",
            "prompt": f"{OLLAMA_CONTEXT}\nchat history trucated=[{history}]\nUser Prompt: {prompt}\nBot:",
            "temperature": OLLAMA_TEMPERATURE,
            "stream": False  # Asegura respuesta completa
        }
        await client.send_chat_action(message.chat.id, ChatAction.CHOOSE_STICKER)  #muestra un estado del bot para saber que está recibiendo el mensaje para ser procesado
        print(f"probando servidor:{alias}")

        try:
            async with aiohttp.ClientSession() as session:
                async with session.post(OLLAMA_URL, json=payload) as response:
                    print(f"response.status={response.status}")
                    if response.status == 200:
                        result = await response.json()
                        return result["response"], alias
                    else:
                        raise Exception(f"Error {response.status}: Unexpected reply")

        except Exception as e:
            print(f"Error con el servidor {SERVER_INDEX}: {e}")
            await message.reply(f"Error con el servidor {SERVER_INDEX}: {e}")
            SERVER_INDEX = (SERVER_INDEX + 1) % len(OLLAMA_SERVERS)  # Pasar al siguiente servidor
            await message.reply(f"Servidor cambiado al índice {SERVER_INDEX} ({OLLAMA_SERVERS[SERVER_INDEX][2]})")
    
    return "No hay servidores disponibles.", ""

@bot.on_message(filters.private & filters.text)
async def chat_handler(client, message):
    """Procesar mensajes privados."""
    print(f"________________________________________________________________________________")
    print(f"user={message.from_user.username}: {message.text}")
    print(f"____________________")
    if not await msg(client, message):
        return

    if message.text.startswith("/"):
        await processCommand(message)
        return

    prompt = message.text
    response, alias = await query_ollama(prompt, client, message)
    #response = re.sub(r"<think>(.*?)</think>", r"<i>\1</i>", response) 
    response_no_thninking=remove_thinking_tags(response)
    response = response.replace("<think>", "<blockquote>").replace("</think>", "</blockquote>")
    print (f"new response={response}")
    LLM_HEADER = f"<b>{alias}[{SERVER_INDEX}] Reply</b> :\n"
    
    # Guardar en el historial
    update_conversation_history(message.from_user.id, prompt, response_no_thninking)
    
    await message.reply(f"{LLM_HEADER}{response}")
    print(f"{LLM_HEADER}{response}")

async def msg(client, message):
    msgNotAllowed = "You're not authorized to use this bot."
    if message.from_user.username not in config["authorized_users"] and config["authorized_users"][0]!="*":
        await message.reply(msgNotAllowed)
        print(msgNotAllowed)
        return False
    return True


async def processCommand(message):
    global OLLAMA_CONTEXT, OLLAMA_TEMPERATURE, SERVER_INDEX, MAX_HISTORY, CONVERSATION_HISTORY
    
    if message.text == "/help": #====================================================== HELP
        msg   =  "Comandos disponibles:"
        msg += "\n/help - Mostrar ayuda"
        msg += "\n/context - Ver o cambiar el contexto"
        msg += "\n/temperature - Ver o cambiar la temperatura"
        msg += "\n/server - Ver o cambiar el servidor actual"
        msg += "\n/reload - recargar la configuración del bot"
        msg += "\n/list - lista de servidores"
        msg += "\n/historymax - especifica cuantos mensajes máximo tiene el historial del chat para el bot. Es la memoria 'persistente' para el bot."
        msg += "\n/historylist - lista los últimos 10 mensajes del historial"
        
        await message.reply("Comandos disponibles:\n/help - Mostrar ayuda\n/context - Ver o cambiar el contexto\n/temperature - Ver o cambiar la temperatura\n/server - Ver o cambiar el servidor actual")
    
    elif message.text.startswith("/temperature"):  #=================================== TEMPERATURE
        try:
            _, new_temp = message.text.split(" ", 1)
            new_temp = float(new_temp)
            if 0.0 <= new_temp <= 1.0:
                OLLAMA_TEMPERATURE = new_temp
                await message.reply(f"Temperatura establecida en {OLLAMA_TEMPERATURE}")
                update_config("temperature",OLLAMA_TEMPERATURE)
            else:
                await message.reply("Error: La temperatura debe estar entre 0.0 y 1.0.")
        except:
            await message.reply(f"Temperatura actual: {OLLAMA_TEMPERATURE}\nPara configurar: /temperature [0.0 - 1.0]")

    elif message.text.startswith("/context"):  #======================================= CONTEXT
        try:
            _, new_context = message.text.split(" ", 1)
            OLLAMA_CONTEXT = new_context
            await message.reply(f"Contexto actualizado:\n{OLLAMA_CONTEXT}")
            update_config("context",OLLAMA_CONTEXT)
        except:
            await message.reply(f"Contexto actual: {OLLAMA_CONTEXT}\nPara configurar: /context [nuevo contexto]")
    
    elif message.text.startswith("/server"):  #======================================== SERVER
        try:
            command_text = message.text.replace("_", " ")  # Reemplaza "_" por " "
            _, new_index = command_text.split(" ", 1)
            new_index = int(new_index)
            if 0 <= new_index < len(OLLAMA_SERVERS):
                SERVER_INDEX = new_index
                await message.reply(f"Servidor cambiado al índice {SERVER_INDEX}\n{OLLAMA_SERVERS[SERVER_INDEX][2]}")
                update_config("server_index", SERVER_INDEX)
            else:
                await message.reply("Error: Índice fuera de rango.")
        except:
            await message.reply(f"Servidor actual: {SERVER_INDEX}\n{OLLAMA_SERVERS[SERVER_INDEX][2]}\nPara cambiar: /server [índice]")

    elif message.text.startswith("/reload"):  #======================================== RELOAD
        load_config()
        msg = "Configuración cargada..."
        await message.reply(msg)
        print(msg)
        
    elif message.text == "/list":  #=================================================== LIST
        servers_list = "Lista de servidores:\n"
        for index, (host, port, alias, model) in enumerate(OLLAMA_SERVERS):
            servers_list += f"/server_{index} - {alias}\n"
        servers_list += f"\nServidor actual: {SERVER_INDEX}\n{OLLAMA_SERVERS[SERVER_INDEX][2]}"
        await message.reply(servers_list)
        print(servers_list)
        
    elif message.text.startswith ("/historymax"):  #===================================== HISTORYMAX
        try:
            _, new_index = message.text.split(" ", 1)
            new_index = int(new_index)
            if 0 <= new_index < 100:
                MAX_HISTORY = new_index
                await message.reply(f"Se ha configurado el máximo del hisorial en {new_index} mensajes")
                update_config("max_history",MAX_HISTORY)
            else:
                await message.reply("Error: Índice fuera de rango.")
        except:
            await message.reply(f"El máximo del hisorial actual es: {MAX_HISTORY} mensajes")

    elif message.text.startswith("/historylist"):  #==================================== HISTORYLIST
        user_id = message.from_user.id
        CONVERSATION_HISTORY[user_id] = load_conversation_history(user_id)
        if user_id in CONVERSATION_HISTORY and CONVERSATION_HISTORY[user_id]:
            history_text = "\n".join(CONVERSATION_HISTORY[user_id][-10:])  # Muestra los últimos 10 mensajes
            history_text = truncate_message(history_text)
            await message.reply(f"Historial reciente (últimos 10 mensajes):\n{history_text}")
        else:
            await message.reply("No hay historial disponible.")

def truncate_message(message, limit=2048):
    """Trunca el mensaje manteniendo solo los últimos 'limit' caracteres."""
    return message[-limit:] if len(message) > limit else message

def remove_thinking_tags(chat_history):
    """Elimina los tags <thinking> y su contenido del texto."""
    return re.sub(r"<think>.*?</think>", "", chat_history, flags=re.DOTALL).strip()

def main():
    print ("Bot initiated...")
    bot.run()
    
if __name__ == "__main__":
    asyncio.run(main())
